{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prototypical Networks - Torchmeta.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4gGudMUnZX/CSElAWjJG7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdoorash/Prototypical-Networks-Implementation-/blob/master/Prototypical_Networks_Torchmeta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDy44raIdPMc",
        "colab_type": "text"
      },
      "source": [
        "## Install Torchmeta (learn-to-learn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWohyf4bdAoV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "7f171776-09d1-405b-f3b0-62ff0b71bcc4"
      },
      "source": [
        "! pip install torchmeta"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchmeta\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/00/ede6d5a91b4765d4b9f23b96bf75fe88bb17fa38d778b840bf6f9809fb8e/torchmeta-1.4.4-py3-none-any.whl (167kB)\n",
            "\r\u001b[K     |██                              | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision<0.7.0,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from torchmeta) (0.6.0+cu101)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from torchmeta) (7.0.0)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from torchmeta) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from torchmeta) (1.18.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torchmeta) (2.10.0)\n",
            "Requirement already satisfied: torch<1.6.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchmeta) (1.5.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchmeta) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torchmeta) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.6.0,>=1.4.0->torchmeta) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchmeta) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchmeta) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchmeta) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchmeta) (3.0.4)\n",
            "Installing collected packages: torchmeta\n",
            "Successfully installed torchmeta-1.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHtwV3jYdMA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchmeta\n",
        "from torchmeta.modules import MetaBilinear, MetaModule, MetaBatchNorm2d, MetaSequential, MetaConv2d\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt \n",
        "from tqdm import tqdm\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU1Eo9e0qQ6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPM_057gfd6c",
        "colab_type": "text"
      },
      "source": [
        "## An example from Torchmeta website "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHEnnGrJeQYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Dataset object for Omniglot and Dataloader...\n",
        "\n",
        "from torchmeta.datasets.helpers import omniglot\n",
        "from torchmeta.utils.data import BatchMetaDataLoader\n",
        "\n",
        "\n",
        "# define the dataset and dataloader\n",
        "om_dataset = omniglot(\"data\", shots=5, ways=5, test_shots=15, meta_train=True, download=True)\n",
        "om_dataloader = BatchMetaDataLoader(om_dataset, batch_size=16)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwOXce8XqM_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ityZMmYaf-gz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "8fe8c33b-e593-48ec-a3ef-dd31d1d2b1ff"
      },
      "source": [
        "# Data insight ...\n",
        "plt.figure(figsize=(16,6))\n",
        "for image in range(4):\n",
        "  plt.subplot(1, 4, image+1)\n",
        "  plt.imshow(om_dataset.dataset[0][image][0].squeeze())\n",
        "  plt.axis('off')\n",
        "  \n",
        "  "
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAADQCAYAAACusvTKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAATeklEQVR4nO3dZ7DddZ3H8VvTO2mkk4QQahAQpeiACiNgA1RQEQVxgwRYFwnLOK6oK6uLDiuK7mLfBRkERQQZKSooTVogCAFD6CUhlSQkpNx7zj5wH+zML58/eHNzC3m9Hvqec8/fnPrlzPy+jfV6vQEAAAD+v6buvgAAAAB6HsMiAAAABcMiAAAABcMiAAAABcMiAAAABcMiAAAAhZaqeFjTh+zVgIaGhptrVzV29zVsidco/I3XKPRsXqPQs6XXqF8WAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKBgWAQAAKLR09wUAAAD0aI2NFW0b/P5Wr1W0euffX+CXRQAAAAqGRQAAAAqGRQAAAAqGRQAAAAqGRQAAAAqGRQAAAApWZwAAAFRomTA+tgVf2DG2cZNXxPbqptbYBn9/aGz9fnNPbJ3NL4sAAAAUDIsAAAAUDIsAAAAUDIsAAAAUDIsAAAAUDIsAAAAUrM4AXreWiRNiW3LkxNhqLY2xNW+oxzbmlsWxtT39XGwNtfbcAGhoaKx4Xx4xPLba6jWx1dvatuqSoCdreyF/J+n/7KTY7njv1bFd+Upej3HJ+g++vgvbxvyyCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMHqDDpF87B89O/SD+0WW8v6vDZh6OV35zus59ux7by669jYZn/217GNb10Z25SWVbH9+LSDYpv3+X1i63PjfbH1Bo19+8b26uGzYtswrLnTr6U9X0rDgOV5RUn/a+/PN7Ta5DW1TK5YRTN4YIf+ZmOtFlv9mRfy/a1b16H7o/s19esX27IT3hTbpBMXxbbmvL1ia75l3uu7MOiFGpvzZ+yGnTfGNndJfq09eGb+TO8zf2FstYrVN539HdkviwAAABQMiwAAABQMiwAAABQMiwAAABQMiwAAABQMiwAAABR6zeqMxtY+sbUdtEdsmwfn/4v9lm3I93f/Y7HVN2+KrderOIq3dvDesS2buz62C3e/JLZ/uHJ2bHkZB92l7x2PxnbNsQfnG1Y8r1bsMyK2Q866K7ZZ//ZgbAufmhZb+8InYuspmgYPim38uY/H9sPJN8bW2piP/F5fz+9p8zf1j+2Tv8mv3xnX5/urb0erM5r2mBnbohOHx3bc4bfH9p4h+blfZVNDfkxOnXdCbIOuGxzbiMvzipQ39GdlD9LYkr/nPPO5vGLo1lO/Edt1r+T30J/sMDW2ji112b40z8j/tk+cODq2WsU39oolCg0jH8xrFIbdkD/T219eXfFXt0+1/fMquO8c/LPYzr705NimLsrfSRZctEu+3c/y49ry+4rVVR3gl0UAAAAKhkUAAAAKhkUAAAAKhkUAAAAKhkUAAAAKhkUAAAAKvWZ1RvPYfJzwjl/PR8mfPfam2J5rGxbb5370qdgmXlhxVPjGjbH1Bi1TJsW204ULYhvX9+XYPnvRqbFN/+nDsbXX87HAdI/aunU5LljYob85bEE+9PsPrQfEdsV5+dj3Dx86N7aRvWB1Rv3VvNbnrofz0d2tU34X26pa/pvfXvHW2O48e//YZt6fH/N2axMaGhoaGl6dnNdOfOLdt8R2w4v5cf71ZW+Lrbnin33N9Lyy5Kr3fie2cfvnP/qOnc6JbcrX58VW25Cfj2xBxfqhtUfvG9uPP5Uf1/c89MnYRp6Tf0sY+Oh9sfHaNo3Pi8E+cFReFzWmdU1sA5ryd899jns6tgvmHBHbwmsOjG3CZYtia39paWy9QdPg/J79wtz87zx//eTYdrp8SWz1QQNi23Pa87EtGzMltiGxdIxfFgEAACgYFgEAACgYFgEAACgYFgEAACgYFgEAACgYFgEAACj0mtUZ7UuXxfbk+bNim3PGDrHdusc1sY2bfWFspz96Zmz9r7knth6j4gjup48fH9vJQ/Mx79897UOxjfl9PgraeoztQ8v4cbEtOjUfN33K0Xn1zbTWQbGtnpGfVyMrnv8NXfl8rLiOl07cK7ZfHH5RbDNuOC22yb/I99dveV5j0OeB+bG1t7XFxt/0uyn/+915z8TYBq99MbaBG57Md1jxvBp0bF6D8uBheW3SvkPzse+/PimvsDn95jmxNd7xYGyUmneeGtvxX7ohti89/b7YRp2eV6K0PfXM67sw/m4tt+eVYX85fFRuTXmFXMPQvO7hiovfHNuNu18V26IzrovtuINOiW3S7Pw52r4sf5fvKWq7TontP/a8PLYzfzg7tgmL8vfghsaK3+2OzSv+hq59ILbO/ibjl0UAAAAKhkUAAAAKhkUAAAAKhkUAAAAKhkUAAAAKhkUAAAAKPWp1RmNrn9jaDtg93+6MpbF9a+efx3bwQx+J7fSd8pqIFz+cj5uedm1zbA219ty6UPOI4bEdfHQ+ivef7zsmtum35aOgm0aOjG3p+6fHNub6p2JrW5yPcqd7tL1j39gGfunZ2K6b/M3Yzlh0XGzLN+ejwifutTi2xj75faa+cWNsna15xrTYPviZP8T2mQUfi23Xc/Nx91VHlltgs+3UN+fPi44eI9/Yt29sq495U2zn/etPYlvSNjS2Xb+fV7LcfPIFsS3fq39so+6IaftVsfbkiRPz2oRZ/fPr/tovHhpb/SnrS7pDR98TWnYcG9ujc/LKjat2/nZse176j7ENqtie8sO5F8c255jTYxt5Sc9fnfHkMXktV5Xxf1yXY9VarnqeDdqXr+jQtXQ2vywCAABQMCwCAABQMCwCAABQMCwCAABQMCwCAABQMCwCAABQ6PrVGU15tcRLn94vtvP+6X9iu+uVvH7hlK9+NrbR1y6K7cKfviu24UPWx9Yb1KaOj+19I66K7e678pHsVSsH2nYeF9tRZ/wpttuePSC2Vqsztk7FEe0tkybEtvLA/Nw58Ox7YhvdZ21sJ3zx7NhGXr8wtqvPyc+POUf9NrabR+8RW9tzz8fW2dbNGBHbuwbnVTQ3fe/tsbUve3yrrmlL1nzkrbFtGpKfR6N+dG9s9ba2rbqm7UFTv36xPX3OPrFdfXJeRfPNJYfH9tQXdoltytKVsT1/Yl6PsXlgfn5Qato9PwbnHPur2M574v2x9b17QWz1iu9jLePymoba6jW5rc3v9by2qhVyj50zJbZbj86v+3deMTe26efnz5rGljwiXPzxd8Y25vi8c6N+2cAt/u+1dRVrJ7aFiu9A7WPzapNfrnxzbC0Lns5/83VdVM/ll0UAAAAKhkUAAAAKhkUAAAAKhkUAAAAKhkUAAAAKhkUAAAAKXb46o2X0yNgOOGlebFcs3T+21aeNiW2Hh/4cW3tjnpXr9eGx9XbL9x4U29r2fAz6jre9HFut4v6a5+cVJfd8YlZs/Z7MaxN6+zHE3a156JDYVl/SGtvVu+Xjub+05LDY7j9339iGX39XbFWP84AX8tHXhwz4a2y/mfaO2Jq7cHXGK+PysfUb6vkx6LMqH+u9LSzLD11DbXRemTP6v/PHi9UZr23ZCXlV0Y2nXBDbIbeeGdvMr6yKrXXR/bE1TZkU2yMb8zqdjftWHIdfcXR9Q72eWy/X2LdvbE/+S16bMK3P0tja/jOvueizOa8xaJmQH7vhV+bH7pGf7Rnb6O/eGRv/p2Jlyarj8xvutUdfmP9kxd1N2+/Z2JZ+NK+SGnlJ/my+47G86u6YWfm7/KOtg2PrSk2D8vfgA2c8EduNf901tulrHtqqa+rJ/LIIAABAwbAIAABAwbAIAABAwbAIAABAwbAIAABAoctPQ63vMCy2w4fdEdtvV+XTt+adm08Qa1lwQGyTv5FPbOr1Kk6aW/GWzbHd+8pO+U8uXt6hS6mtqzgR78EFHfqbbKXmfBrbSyvzSanrKw4pfHRVPpFv4POvxFbr4KmIY+9aG9uKMwfEtnSffrHteGu+lM62Nr/UGu5bPzW21qdeim1bnDG685cfia2xOf/3xvYNG7bB1byxNI8aFdv+sx+I7csvvju2meevyXe4fGW+lmFDY2tfnJ9zX5t3RGwf3+Pu2O4ekd8v2lfk6+ztmqbmk2W/vPd1sZ30h0/FNuNX93TsYiree2cNeS62Bwft1rH7o6GhoaGhsTV/9V56aP5+1t6QH6/Tnzo2ttUb82deh7VXfG73Ak0V73f7DX04tjtX7pL/aO2Ne06/XxYBAAAoGBYBAAAoGBYBAAAoGBYBAAAoGBYBAAAoGBYBAAAodPnqjMYVL8d21l0fjm23SYtjm7Hj0tgeXTI5X0xTnpXXb2yNbdrIFbFt7p+PKK5aIdHYsuWHorFPXgtSqWI1wtjxq2L70+LpsY1Y9kTHroUep+po+umz89Hdx550Tmxz5/w8tmcuHRnb9V89NLZBV/45tuZn8nH+VasnNoyu2P/RQ2yu59dvvVbrwitpaKitzStK2Drr3zwltq+M/VZsz7Tlz6drr3xTh65lyca8MufJuRWrEl7Mn3m77Jc/t+8ZkF+jDb19dUbFSopFH8/vhTP7LIlt8tUV91exYqhK2wv58bnp1LfFNmlJvt0bd3lA56lv3Bjbbp/PK0s+N/3U2FrmLYxtyIaKtWf1J3PrShWvmaZBg/LNxo2JrV6xouTl3fIav7cNyC+2yx7Kq4LeyPyyCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQKHLV2e0LcnH3c/4dF6r0V6xCqLKzu0PxFarOL649tDQ2L7wyZ/GdvzXTo+tZV2ezTeP2fK6gt2nvhBv01H/PumXsc2Z/9FOvz96l6pVCWMuvju2Hzx+TGxDzs3Hga8bk18X+cBs6P0G3P7X2N7+X3Nje3Xaps6/mE35dThz1ZrYBizuH9uB/fPr/kdTR8XW9NzzsfUGLTvllV1nfeDa2I6/95TYpvxufmwdXgZUy4summ5/MDbrMbadqu/ITRWtaxcqVTtyWH6uXnPep7f4v9db8rN471l5vcfxY2+ObVjT+tiGNG2ouF1+f+2/oif9S3cdvywCAABQMCwCAABQMCwCAABQMCwCAABQMCwCAABQMCwCAABQ6PLVGVXqFassOnw0dAeNuy1fyyVHHBrbyYf8sUP3t2Tjlld1/P7pGfE27W0dm/VPev6k2CZeXvGUqDhmm+1ExXOg7w33xbb59rwEY+ym+2Pr6tc9dKX2NXklxcTz7+zCK6lWdVj80GlviW1zxQu41pI/v3rFf8VubIzphfeMi+2wgXldyqW/eG9s9c3bYF0KdNCgx1tjm3fAlNjmHHbT331fv1s2M7bzLvtYbP1W/N139bfbrczveMNu+ktsb+SlGr3iPRkAAICuZVgEAACgYFgEAACgYFgEAACgYFgEAACgYFgEAACg0KNWZ/QkLbfMi23xUcNza5nUsTtsa9vi/zxp5cP5NnWLBehBKp6PtbVru/BCALat5h1GxHbkSbfHdsrCfNT/kN8+Etsb+Vh+ep/xF+WVV7f8ZGq+YVNeOZPU174c26T1XbtiaHt9HfplEQAAgIJhEQAAgIJhEQAAgIJhEQAAgIJhEQAAgIJhEQAAgILVGUnFGoD2FSu78EJg+9U8ZnRsG/acGNtOfe+ObfOw9nx/u+/y+i6sE1Rdx4Q+Fe8xg/fI7aWtuCDoZGOa81eMtWetiW3Zx/bbFpfTqQYMfTW2K0ddH9u+1x8U25S1z2zVNUFXqW/cGFv7smVdeCV0Bb8sAgAAUDAsAgAAUDAsAgAAUDAsAgAAUDAsAgAAUDAsAgAAULA6A+hWzSN3iG3JD4bH9r09vh/bW/s1x7bvERfG9ti7RsbW2Wa2Lo/t6bahsdWGDdwWlwMdMvD59bGd8syRsR0xYUH+oxO25oq6xjsHPxLbd1ftGdtOv8orQ/LCLoDu45dFAAAACoZFAAAACoZFAAAACoZFAAAACoZFAAAACoZFAAAAClZnAN2q/sq62DbfvktsH1k+O7Yh8/vE1tT2+q6rOw16sT22gfMf6MIrgWr1+x6ObfW7B8V2b3PXranpsMb839Pv3XH3fLt6XoJRf6xiZQhAD+SXRQAAAAqGRQAAAAqGRQAAAAqGRQAAAAqGRQAAAAqGRQAAAApWZwDdqrZhQ2zjLrizC6+kd8iH8kM3qFgTUVu7tgsvpIutWtXdVwDQJfyyCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQMGwCAAAQKGxXq939zUAAADQw/hlEQAAgIJhEQAAgIJhEQAAgIJhEQAAgIJhEQAAgIJhEQAAgML/Av9eFuw6tfoAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1152x432 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6e-OX63i8PX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3c81453f-c2bf-44bf-c440-9145b36f94b8"
      },
      "source": [
        "for batch in om_dataloader:\n",
        "  t_input, t_target = batch[\"train\"]\n",
        "  print('Train input shape: {}'.format(train_inputs.shape))\n",
        "  print('Train target shape: {}'.format(train_target.shape))\n",
        "\n",
        "  t_inputs, t_target = batch[\"test\"]\n",
        "  print('Test input shape: {}'.format(test_inputs.shape))\n",
        "  print('Test target shape: {}'.format(test_target.shape))\n",
        "  \n",
        "\n",
        "  break\n"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train input shape: torch.Size([16, 25, 1, 28, 28])\n",
            "Train target shape: torch.Size([16, 25])\n",
            "Test input shape: torch.Size([16, 75, 1, 28, 28])\n",
            "Test target shape: torch.Size([16, 75])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpwhvo_rzQnX",
        "colab_type": "text"
      },
      "source": [
        "### Prototypical Networks Architecture \n",
        "* with help of MAML example presented in the Torchmeta homepage. I use the same code with little changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKMg9RmWzcau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the scheme of the Prototypical Networks convolution blocks ...\n",
        "def convblock(in_channels, out_channels):\n",
        "  return MetaSequential(\n",
        "      MetaConv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "      MetaBatchNorm2d(out_channels),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2)\n",
        "  )\n",
        "\n",
        "# Build the architecture of the embedding mirrors .....\n",
        "class ConvolutionNNEmbedding(MetaModule):\n",
        "  def __init__(self, in_channels, out_channels, hidden_size=64):\n",
        "    super(ConvolutionNNEmbedding, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.encoder = MetaSequential(\n",
        "        convblock(in_channels, hidden_size),\n",
        "        convblock(hidden_size, hidden_size),\n",
        "        convblock(hidden_size, hidden_size),\n",
        "        convblock(hidden_size, out_channels)\n",
        "      )\n",
        "    \n",
        "\n",
        "  \n",
        "  def forward (self, inputs):\n",
        "        embeddings = self.encoder(inputs.view(-1, *inputs.shape[2:]))\n",
        "        return embeddings.view(*inputs.shape[:2], -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qaxg2jDcvpj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_channels, out_channels, **kwargs):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, **kwargs),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "class PrototypicalNetwork(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, hidden_size=64):\n",
        "        super(PrototypicalNetwork, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            conv3x3(in_channels, hidden_size),\n",
        "            conv3x3(hidden_size, hidden_size),\n",
        "            conv3x3(hidden_size, hidden_size),\n",
        "            conv3x3(hidden_size, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        embeddings = self.encoder(inputs.view(-1, *inputs.shape[2:]))\n",
        "        return embeddings.view(*inputs.shape[:2], -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UYDyH1tjebW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6ffa63d-21ae-4c07-9a71-2c0f6d98a856"
      },
      "source": [
        "x = torch.randn((32, 25,1,28,28))\n",
        "x.shape\n"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 25, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HP4w-c7WU2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5221f30a-1f01-4e65-e7d9-31984df02374"
      },
      "source": [
        "model = PrototypicalNetwork(1, 64)\n",
        "x_embedding = model(x)\n",
        "x_embedding.shape"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 25, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHFJuTRi0P6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_samples(targets, num_classes, dtype=None):\n",
        "    batch_size = targets.size(0)\n",
        "    with torch.no_grad():\n",
        "        ones = torch.ones_like(targets, dtype=dtype)\n",
        "        num_samples = ones.new_zeros((batch_size, num_classes))\n",
        "        num_samples.scatter_add_(1, targets, ones)\n",
        "    return num_samples\n",
        "\n",
        "\n",
        "# This function to get the prototypes of each class\n",
        "def get_prototypes(embeddings, targets, num_classes):\n",
        "    batch_size, embedding_size = embeddings.size(0), embeddings.size(-1)\n",
        "    \n",
        "    num_samples = get_num_samples(targets, num_classes, dtype=embeddings.dtype)\n",
        "    num_samples.unsqueeze_(-1)\n",
        "    num_samples = torch.max(num_samples, torch.ones_like(num_samples))\n",
        "\n",
        "    prototypes = embeddings.new_zeros((batch_size, num_classes, embedding_size))\n",
        "    indices = targets.unsqueeze(-1).expand_as(embeddings)\n",
        "    prototypes.scatter_add_(1, indices, embeddings).div_(num_samples)\n",
        "\n",
        "    return prototypes\n",
        "\n",
        "\n",
        "# Compute the prototypical loss using Euclidean distance ...\n",
        "\n",
        "def prototypical_loss(prototypes, embeddings, targets, **kwargs):\n",
        "    squared_distances = torch.sum((prototypes.unsqueeze(2)\n",
        "        - embeddings.unsqueeze(1)) ** 2, dim=-1)\n",
        "    return F.cross_entropy(-squared_distances, targets, **kwargs)\n",
        "\n",
        "\n",
        "# Compute the mean acuuracy on query points...\n",
        "def get_accuracy(prototypes, embeddings, targets):\n",
        "  \n",
        "    sq_distances = torch.sum((prototypes.unsqueeze(1)\n",
        "        - embeddings.unsqueeze(2)) ** 2, dim=-1)\n",
        "    _, predictions = torch.min(sq_distances, dim=-1)\n",
        "    return torch.mean(predictions.eq(targets).float())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6G4m6tspueG",
        "colab_type": "text"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Qsd-O-pyy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train (model, dataloader, in_channels, out_channels, optimizer):\n",
        "\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  \n",
        "  for batch_idx, batch in enumerate(dataloader):\n",
        "    model.zero_grad()\n",
        "\n",
        "    train_inputs, train_targets = batch['train']\n",
        "    train_inputs = train_inputs.to(device)\n",
        "    train_targets = train_target.to(device)\n",
        "    train_embeddings = model(train_inputs)\n",
        "\n",
        "    test_inputs,  test_target = batch['test']\n",
        "    test_inputs = test_inputs.to(device)\n",
        "    test_targets = test_target.to(device)\n",
        "    test_embeddings = model(test_inputs)\n",
        "\n",
        "\n",
        "    prototypes = get_prototypes(train_embeddings, train_targets, dataloader.dataset.num_classes_per_task)\n",
        "    loss = prototypical_loss(prototypes, test_embeddings, test_targets)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "            accuracy = get_accuracy(prototypes, test_embeddings, test_targets)\n",
        "            print('Accuracy={0:.4f}'.format(accuracy.item()))\n",
        "    \n",
        "    if batch_idx >= 100:\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqJ1rg6O30Lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "in_channels = 1\n",
        "out_channels = 64\n",
        "# om_dataloader.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr_aEmO156yl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "089d7812-468d-4581-c2ca-0ddab8e1fcca"
      },
      "source": [
        "train(model, om_dataloader, in_channels, out_channels, optimizer)"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy=0.2367\n",
            "Accuracy=0.1792\n",
            "Accuracy=0.2575\n",
            "Accuracy=0.1950\n",
            "Accuracy=0.2308\n",
            "Accuracy=0.1767\n",
            "Accuracy=0.2533\n",
            "Accuracy=0.2633\n",
            "Accuracy=0.1900\n",
            "Accuracy=0.2050\n",
            "Accuracy=0.1800\n",
            "Accuracy=0.2142\n",
            "Accuracy=0.1783\n",
            "Accuracy=0.1858\n",
            "Accuracy=0.2233\n",
            "Accuracy=0.2383\n",
            "Accuracy=0.1975\n",
            "Accuracy=0.2292\n",
            "Accuracy=0.1358\n",
            "Accuracy=0.2492\n",
            "Accuracy=0.2158\n",
            "Accuracy=0.1858\n",
            "Accuracy=0.1992\n",
            "Accuracy=0.2658\n",
            "Accuracy=0.1667\n",
            "Accuracy=0.2067\n",
            "Accuracy=0.1825\n",
            "Accuracy=0.2325\n",
            "Accuracy=0.1300\n",
            "Accuracy=0.2775\n",
            "Accuracy=0.1792\n",
            "Accuracy=0.2408\n",
            "Accuracy=0.1983\n",
            "Accuracy=0.1917\n",
            "Accuracy=0.1725\n",
            "Accuracy=0.2425\n",
            "Accuracy=0.2017\n",
            "Accuracy=0.1692\n",
            "Accuracy=0.1558\n",
            "Accuracy=0.1933\n",
            "Accuracy=0.1942\n",
            "Accuracy=0.2008\n",
            "Accuracy=0.1867\n",
            "Accuracy=0.2000\n",
            "Accuracy=0.1608\n",
            "Accuracy=0.1900\n",
            "Accuracy=0.1625\n",
            "Accuracy=0.1750\n",
            "Accuracy=0.2000\n",
            "Accuracy=0.1883\n",
            "Accuracy=0.1958\n",
            "Accuracy=0.1367\n",
            "Accuracy=0.1883\n",
            "Accuracy=0.2167\n",
            "Accuracy=0.1900\n",
            "Accuracy=0.1717\n",
            "Accuracy=0.1967\n",
            "Accuracy=0.1850\n",
            "Accuracy=0.1425\n",
            "Accuracy=0.1508\n",
            "Accuracy=0.1717\n",
            "Accuracy=0.2392\n",
            "Accuracy=0.1450\n",
            "Accuracy=0.2267\n",
            "Accuracy=0.1950\n",
            "Accuracy=0.1950\n",
            "Accuracy=0.2200\n",
            "Accuracy=0.2008\n",
            "Accuracy=0.1900\n",
            "Accuracy=0.1883\n",
            "Accuracy=0.2250\n",
            "Accuracy=0.1650\n",
            "Accuracy=0.1800\n",
            "Accuracy=0.1458\n",
            "Accuracy=0.2508\n",
            "Accuracy=0.1983\n",
            "Accuracy=0.1442\n",
            "Accuracy=0.1933\n",
            "Accuracy=0.2158\n",
            "Accuracy=0.1333\n",
            "Accuracy=0.2067\n",
            "Accuracy=0.1808\n",
            "Accuracy=0.2392\n",
            "Accuracy=0.2258\n",
            "Accuracy=0.1892\n",
            "Accuracy=0.2258\n",
            "Accuracy=0.1817\n",
            "Accuracy=0.2275\n",
            "Accuracy=0.1875\n",
            "Accuracy=0.2000\n",
            "Accuracy=0.1600\n",
            "Accuracy=0.2367\n",
            "Accuracy=0.1767\n",
            "Accuracy=0.1783\n",
            "Accuracy=0.2333\n",
            "Accuracy=0.2508\n",
            "Accuracy=0.2175\n",
            "Accuracy=0.2242\n",
            "Accuracy=0.1683\n",
            "Accuracy=0.2233\n",
            "Accuracy=0.2367\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}